{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_style_links():\n",
    "    \n",
    "    \"\"\"\n",
    "    No inputs required. \n",
    "    \n",
    "    The styles page on beer advocate is provided within the function as the URL used in scraping.\n",
    "    It was chosen due to the fact that it is the easiest page from which to access all beers within beer advocate.\n",
    "    \n",
    "    Searches through the page and finds any hyperlink containing the string 'beer/styles' and selects the number from the URL.\n",
    "    Then creates links from the initial beer styles URL and the beer styles numbers.\n",
    "    The output is a list of followable links.\n",
    "    \"\"\"\n",
    "    \n",
    "    followable_links = []\n",
    "    url = 'https://www.beeradvocate.com/beer/styles/'\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "    styles_links = [link for link in soup.find_all('a') if 'beer/styles' in str(link)]\n",
    "\n",
    "    styles_nums = []\n",
    "\n",
    "    for link in styles_links[2:]:\n",
    "        styles_nums.append(str(link).split('/')[3])\n",
    "        \n",
    "    styles_nums = sorted(styles_nums)[1:]\n",
    "    \n",
    "    for num in styles_nums:\n",
    "        followable_links.append(url + num)\n",
    "    \n",
    "    return followable_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.beeradvocate.com/beer/styles/16'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_links = get_style_links()\n",
    "style_links[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brew_beer_links(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes a URL of a style page as input and outputs a list of the <= 50 beer profile hyperlinks on that page. \n",
    "    \n",
    "    Note that the name of this function is 'get_brew_beer_links' as opposed to simply 'get_beer_links' as every link to a beer page is a subpage of a brewery.\n",
    "    e.g. 'https://www.beeradvocate.com/beer/profile/' + Brewery_Number + '/' + Beer_Number\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    followable_links = []\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    \n",
    "    beer_links = [link for link in soup.find_all('a') if '/beer/profile/' in str(link)]\n",
    "    \n",
    "    beer_nums = []\n",
    "\n",
    "    for link in beer_links:\n",
    "        beer_num = str(link).split('/')\n",
    "        if len(beer_num) > 6:\n",
    "\n",
    "            # take both brewering number and beer number\n",
    "\n",
    "            brew, beer = beer_num[3:5]\n",
    "            brew_beer = brew + '/' + beer + '/'\n",
    "            beer_nums.append(brew_beer)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    prof_url = 'https://www.beeradvocate.com/beer/profile/'\n",
    "    \n",
    "    for num in beer_nums:\n",
    "        followable_links.append(prof_url + num)\n",
    "\n",
    "    \n",
    "    return followable_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.beeradvocate.com/beer/profile/388/5281/\n"
     ]
    }
   ],
   "source": [
    "brew_beer_links = get_brew_beer_links(style_links[0])\n",
    "brew_beer_link = brew_beer_links[0]\n",
    "print(brew_beer_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_style_max(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the URL for a style page as input. \n",
    "    Returns the highest sort value for that styles page.\n",
    "    Each style has anywhere between 10s and tens of thousands of beers. The highest sort value indicates the last page for each style.\n",
    "    For style with fewer than 50 beers the function will be unable to pull a value and will thus set the value equal to 0.\n",
    "    \n",
    "    The output of this will be used to ensure that the compiler function never attempts to go beyond the number of pages available for a particular style. If it were to do so, it would either cause an error or continue infinitely.    \n",
    "    \"\"\"     \n",
    "\n",
    "\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    \n",
    "    try:\n",
    "        style_max_ref = soup.find_all('a')[-137]\n",
    "        style_max = re.split(r'=|\"', str(style_max_ref))[-2]\n",
    "        style_max = int(style_max)\n",
    "    except:\n",
    "        style_max = 0\n",
    "    \n",
    "    return style_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_max = get_style_max(style_links[0])\n",
    "style_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do I also want to separately track score within beer type??? I don't think I've gotten that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beer_info(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes a link to a beer page as input, scrapes the page and stores the contents in a dictionary.\n",
    "    \n",
    "    The following are the values that will be captured from the beer page:\n",
    "    \n",
    "    score: Average of ratings on Beer Advocate.\n",
    "    beer_class: Categical ranking of Brewery. Outstanding, Good, Okay, etc.\n",
    "    ranking: How the beer ranks against all other beers on Beer Advocate\n",
    "    reviews: The number of reviews for a brewery.\n",
    "    ratings: The number of ratings for a brewery. (Note that reviews are different from ratings in the reviews include a text response while ratings are only numeric).\n",
    "    pDev: The percent deviation of ratings for a brewery.\n",
    "    wants: The number of people that has indicated that they want the beer.\n",
    "    gots: The number of people that has indicated that they have the beer.\n",
    "    trade: The number of people that has indicated that they are willing to trade for the beer.\n",
    "    brew: The name of the brewery that produces the beer.\n",
    "    region: Where the brewery is located.\n",
    "    site: The website for the brewery.\n",
    "    style: The style of the beer.\n",
    "    abv: The Alcohol by Volume\n",
    "    availability: When the beer is available, e.g. Seasonally, winter, year-round, etc.\n",
    "    comm_desc: Notes about the beer.\n",
    "    date_added: When the beer was added to Beer Advocate.\n",
    "    \"\"\"\n",
    "    \n",
    "    key = []\n",
    "    values = []\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    \n",
    "    # Finding feature values\n",
    "    \n",
    "    try:\n",
    "        title_div = soup.find(class_='titleBar')\n",
    "        beer_brew_names = str(title_div.text).replace('\\n','')\n",
    "    except:\n",
    "        beer_brew_names = 'NA'\n",
    "        \n",
    "    try:\n",
    "        score_obj = soup.find('span', {'class': 'BAscore_big'})\n",
    "        score = float(re.split(r'>|<', str(score_obj))[4])\n",
    "    except:\n",
    "        score = np.nan\n",
    "        \n",
    "    try:   \n",
    "        beer_class_obj = soup.find_all('b')[4]\n",
    "        beer_class = re.split(r'>|<', str(beer_class_obj))[2]\n",
    "    except:\n",
    "        beer_class = 'NA'\n",
    "    \n",
    "    stats_objs = soup.find_all('dd')[5:13]\n",
    "    stats_list = []\n",
    "    for item in stats_objs:\n",
    "        item = str(item.text).strip()\n",
    "        if len(item) > 0:\n",
    "            clean_item = re.sub(r'#|%|,','',item)\n",
    "            if '.' in clean_item:\n",
    "                stats_list.append(float(clean_item))\n",
    "            else:\n",
    "                stats_list.append(int(clean_item))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    if len(stats_list) < 7:\n",
    "        stats_list = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "    \n",
    "    ranking, reviews, ratings, pDev, wants, gots, trade = stats_list\n",
    "\n",
    "    brew_objs = soup.find_all('a')[119:122]\n",
    "    brew_objs_list = []\n",
    "    for obj in brew_objs:\n",
    "        brew_objs_list.append(obj.text)\n",
    "    brew, region, site = brew_objs_list\n",
    "\n",
    "    try:\n",
    "        info_div = soup.find('div',attrs={'id':'info_box'})\n",
    "        info_sub_div = re.split(r'</b></a>\\n<br/><br/>\\n<b>',str(info_div))[-2]\n",
    "        style = info_sub_div.split('/\"><b>')[-1]\n",
    "        style\n",
    "    except:\n",
    "        style = 'NA'\n",
    "    \n",
    "    # checks length to handle exceptions when ABV is not provided\n",
    "    \n",
    "    abv_div = soup.find('div',attrs={'id':'info_box'})\n",
    "    abv_div_list = str(abv_div).split('(ABV):</b>')\n",
    "\n",
    "    try:\n",
    "        abv = float(abv_div_list[1][1:5])\n",
    "    except:\n",
    "        abv = np.nan\n",
    "\n",
    "    try:            \n",
    "        availability_str = str(abv_div).split('Availability:</b> ')[1]\n",
    "        availability = availability_str.split('\\n')[0]\n",
    "    except:\n",
    "        availability = 'NA'\n",
    "    \n",
    "    try:   \n",
    "        comm_desc_str = str(abv_div).split('Description:</b>\\n<br/>\\n')[1]\n",
    "        comm_desc = comm_desc_str.split('<br')[0]\n",
    "    except:\n",
    "        comm_desc = 'NA'\n",
    "        \n",
    "    try:\n",
    "        date_added_str = str(abv_div).split('<br/><br/>')[-2]\n",
    "        date_added = date_added_str.split()[-1]\n",
    "    except:\n",
    "        date_added = 'NA'\n",
    "        \n",
    "    \n",
    "    key = beer_brew_names \n",
    "    \n",
    "    values = [score, beer_class, ranking, reviews, ratings, pDev, \n",
    "                            wants, gots, trade, brew, region, site, style, abv, \n",
    "                            availability, comm_desc, date_added]\n",
    "    \n",
    "    return key, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantillon Fou' Foune | Brasserie Cantillon\n",
      "['4.65', 'World-Class', '23', '562', '3079', '7.31', '2811', '669', '58', 'Brasserie Cantillon', 'Belgium', 'cantillon.be', 'Belgian Fruit Lambic', '5.00', 'Rotating', 'Apricot Lambic', '08-05-2002']\n"
     ]
    }
   ],
   "source": [
    "key, values = get_beer_info(brew_beer_link)\n",
    "print(key)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_new_style_page(url,counter):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes a URL of a style page as input and concatenates it with string used for sorting as well as the counter. The counter is the current sort-by value.\n",
    "    \"\"\"\n",
    "    \n",
    "    out = url + '/?sort=revsD&start=' + str(counter)\n",
    "    \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.beeradvocate.com/beer/styles/10/?sort=revsD&start=0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_new_style_page(style_links[0],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_beer_info():\n",
    "    \n",
    "    \"\"\"\n",
    "    No inputs required.\n",
    "    \n",
    "    Obtains all style links from the style links function.\n",
    "    \n",
    "    For each style link, finds the style max (i.e. the last page of beers for that style) and sets a counter to 0.\n",
    "    \n",
    "    For each style link combined with the counter; obtains a list of urls of all beer pages on the respective style page, scrapes each page, then increase the counter by 50 so as to go to the next style page, obtain a list of beer links, and scrape each beer page.\n",
    "    \n",
    "    The function will then save the dictionary as a pandas DataFrame.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    style_links = get_style_links()\n",
    "    \n",
    "    # pick up where we left off\n",
    "    \n",
    "    style_links = style_links[28:]\n",
    "    \n",
    "    for style_link in style_links:\n",
    "        \n",
    "        style_max = get_style_max(style_link)\n",
    "\n",
    "        # For each style link we add the suffix used\n",
    "        # to sort. Sorting is done in groups of 50.\n",
    "        # Our counter is used to specify where sorting\n",
    "        # will occur on the next loaded page.\n",
    "\n",
    "        # Each style like will have multple pages.\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        while counter <= style_max:\n",
    "            \n",
    "            dic = {}\n",
    "\n",
    "            url = open_new_style_page(style_link,counter)\n",
    "\n",
    "            brew_beer_links = get_brew_beer_links(url)\n",
    "\n",
    "            for brew_beer_link in brew_beer_links:\n",
    "\n",
    "                key, values = get_beer_info(brew_beer_link)\n",
    "\n",
    "                dic[key] = values\n",
    "\n",
    "                time.sleep(np.random.poisson(10)/100)\n",
    "\n",
    "            string = re.findall(r'\\d+', url)\n",
    "            name = str(string[0]) + '_' + str(string[-1])\n",
    "\n",
    "            df = pd.DataFrame(dic)     \n",
    "            df = df.transpose()      \n",
    "            pd.DataFrame.to_pickle(df,name)\n",
    "\n",
    "            counter += 50\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "compile_beer_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
